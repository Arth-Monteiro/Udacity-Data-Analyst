{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452abebc",
   "metadata": {},
   "source": [
    "# Wrangle Report\n",
    "\n",
    "## Summary\n",
    "<ul>\n",
    "    <li><a href=\"#data\">The Data</a></li>\n",
    "    <li><a href=\"#gather\">Gathering Data</a></li>\n",
    "    <li><a href=\"#assess\">Assessing Data</a></li>\n",
    "    <li><a href=\"#clean\">Cleaning Data</a></li>\n",
    "    <li><a href=\"#store\">Storing Data</a></li>\n",
    "</ul>\n",
    "\n",
    "<a id=\"data\"></a>\n",
    "## The Data\n",
    "\n",
    "In this projetct, I will work with three datasets:\n",
    "\n",
    "1. <b>Enhanced Twitter Archive:</b> \n",
    "2. <b>Additional Data via the Twitter API: **</b>\n",
    "3. <b>Image Predictions File</b>:\n",
    "\n",
    "<a id=\"gather\"></a>\n",
    "## Gathering Data\n",
    "\n",
    "- Enhanced Twitter Archive was downloaded manually;\n",
    "- Additional Data via the Twitter API was downloaded manually for now, but I intend to develop using the API Twitter for later;\n",
    "- Image Predictions File was downloaded programmatically. Using the requests module from python, I was able to make a get request for the tsv file and get the file.\n",
    "\n",
    "<a id=\"assess\"></a>\n",
    "## Assessing Data\n",
    "\n",
    "Assessing visually and programmatically the three tables, I looked for Quality and Tidiness issues.\n",
    "\n",
    "- <b>Visually</b>: Each piece of gathered data was displayed in the Jupyter Notebook for visual assessment purposes. But I could use other tools like Google Spreadsheets or Excel.\n",
    "- <b>Programmatically</b>: Using pandas methods I manipulated the data searching for issues that was not so clearly on visual search. After a while and some efforts, I was able to list the above issues.\n",
    "\n",
    "\n",
    "### Issues\n",
    "\n",
    "#### Quality\n",
    "1. On `Image Predictions File`, there is 324 tweets and images that are not about dogs.\n",
    "2. On `Image Predictions File`, the dog breed that was predicted it's joined by an underscore.\n",
    "3. On `Additional Data via the Twitter API`, there is some retweets.\n",
    "4. On `Additional Data via the Twitter API`, there is incompability on some `id` and `id_str` fields.\n",
    "5. On `Additional Data via the Twitter API`, the column `geo` and `coordinates` doesn't have any information.\n",
    "6. On `Enhanced Twitter Archive` there is some registers where in the place of the name of the dog was extracted some misleaded word. By the sample, could be replaced by `NaN`.\n",
    "7. On `Enhanced Twitter Archive` there is some ratings that got wrongly extracted as on `twitter_id` 716439118184652801, 810984652412424192 or 883482846933004288 (three different cases of wrongly extraction)\n",
    "8. On `Enhanced Twitter Archive` where the denominator ratings are different than 10, usually there are more than one dog being rated. And checking visually the images, usually the denominator it's given summerizing 10 times the number of dogs in the picture. So where the denominator is 110, there is 11 dogs.\n",
    "\n",
    "#### Tidiness\n",
    "1. On `Additional Data via the Twitter API` the column `display_text_range` contains two info that can be displayed into two columns.\n",
    "2. On `Enhanced Twitter Archive` fields `doggo`, `floofer`, `pupper` and `puppo` could be just one column\n",
    "3. The information it's spread across many places. Can be merged into one table.\n",
    "\n",
    "\n",
    "<a id=\"clean\"></a>\n",
    "## Cleaning Data\n",
    "\n",
    "First I copy the data into new dataframes to not alter directly on the original ones. \n",
    "\n",
    "For the quality issues, my solution was:\n",
    "- Remove the data that was not about dogs or was not about rates of dogs. \n",
    "- Remove retweets and replys getting just the tweet ids that I wanted to analyze. \n",
    "- Correct the extraction of the rates \n",
    "- Rename the dog name where was not a name to \"None\", since the most cases where I analyzed, didn't has a name in this rows.\n",
    "\n",
    "And for tidiness issues:\n",
    "- Transform the columns `doggo`, `floofer`, `pupper` and `puppo` into one.\n",
    "- Correct the types of columns.\n",
    "- Remove columns that would not be used on my analysis\n",
    "- Transform the column `display_text_range`into a field containing only the last item (the lenght of the tweet text).\n",
    "- Merge the tables into one.\n",
    "\n",
    "\n",
    "<a id=\"store\"></a>\n",
    "## Storing Data\n",
    "\n",
    "At the end, I stored the data so could be access in other oportunities and other people without remake all my steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
